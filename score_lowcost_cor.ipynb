{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sie21/ExamenBigData/blob/master/score_lowcost_cor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "gu_p8Z-s0uCA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "try:\n",
        "    os.remove(\"metastore_db/db.lck\")\n",
        "    os.remove(\"metastore_db/dbex.lck\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "def build_spark_session(app_name, memory='4g', executors=4):\n",
        "    return SparkSession.builder\\\n",
        "                      .appName(app_name)\\\n",
        "                      .config('spark.executor.memory', memory)\\\n",
        "                      .config('spark.executor.instances', executors)\\\n",
        "                      .getOrCreate()\n",
        "\n",
        "spark_session = build_spark_session(app_name='ok-google')\n",
        "\n",
        "from pyspark.sql import functions as f\n",
        "\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "-dHj7ULB0uCH"
      },
      "source": [
        "l'objectif est de predire l'appentence des clients a des transport lowcoast.\n",
        "Pour cela, nous utiliserons la librairie Ml de spark"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "3jrcZGqb0uCI"
      },
      "source": [
        "perimetre: représente les identifaints des clients accessible à l'étude.\n",
        "histo_client: represente l'historique des données clients sur une période donnée\n",
        "histo_train: represente l'historique des données de commandes trains.\n",
        "histo_lowcost: represente l'historique des données de client lowcost (défini avec le métier).\n",
        "visites: représente l'historique des données de navigation des clients sur le site."
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "PdR367zy0uCJ"
      },
      "source": [
        "1 - lire les fichiers de données\n",
        "2 - identifier les variables continues et transformer leurs modalités en double.\n",
        "3 - joindre les differentes sources de données en se basant sur les données du périmètre (tous les individus du périmèetre devront apparaitre dans la jointure avec des valeurs NULL si nécessaire pour les colonnes en provenance d'autres sources)."
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "Mv33WSma0uCJ"
      },
      "source": [
        "1 - joindre les dataframe sur la clé ID_CLIENT en concervant tous les clients \n",
        "du périmètre.\n",
        "\n",
        "2 - compter le nombre de ID_CLIENT et vérifier qu'il correspond aux nombre \n",
        "d'ID_CLIENT dans la variable perimètre.\n",
        "    \n",
        "3 - Caster les variables continues en double et sauvergarder alors le df obtenu \n",
        "dans le repertoire data sur le cluster.\n",
        "    \n",
        "4 - Pour les variables catégorielles, créer une nouvelle variable qui prend \n",
        "la modalité de la variable courante si elle existe et \"NA\" sinon.\n",
        "    \n",
        "5- Verifier la cohérence des variables continue. Par exemple pour une variable\n",
        "comme age mettre à -1 tous les ages <0 ou>120ans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsxZd97k0uCK"
      },
      "source": [
        "#### 1 - lire les fichiers de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "hQ-_HQ8g0uCM"
      },
      "outputs": [],
      "source": [
        "perimetre = spark_session.read.csv(\"data_clients/sample_perimetre.csv\", header=True)\n",
        "histo_client_raw = spark_session.read.csv(\"data_clients/sample_histo_client.csv\", header=True)\n",
        "histo_train_raw = spark_session.read.csv(\"data_clients/sample_histo_train.csv\", header=True)\n",
        "histo_lowcost_raw = spark_session.read.csv(\"data_clients/sample_histo_lowcost.csv\", header=True)\n",
        "visites_raw = spark_session.read.csv(\"data_clients/sample_visites.csv\", header=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaJlY3Wq0uCN"
      },
      "source": [
        "#### 2 - identifier les variables continues et transformer leurs modalités en double."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ_uh1r80uCO",
        "outputId": "ea61547d-06a2-4d17-bdba-047dec143743"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre d'individu : 1084217\n",
            "+--------------------+\n",
            "|           ID_CLIENT|\n",
            "+--------------------+\n",
            "|0023d2b0a410eb572...|\n",
            "|0026decd53a30d9b3...|\n",
            "|002f0b8e5d2236008...|\n",
            "|00352dc1e7e43436f...|\n",
            "|005a10c0d3a94096c...|\n",
            "+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Nombre d'individu : {}\".format(perimetre.count()))\n",
        "perimetre.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ_fUqEm0uCQ"
      },
      "source": [
        "Ce dataframe est composé que des identifiants des clients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65yq5T4c0uCQ",
        "outputId": "bfe4a88f-f4fb-490b-aaf9-66e64f4f6081"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ID_CLIENT',\n",
              " 'anciennete',\n",
              " 'recence_cmd',\n",
              " 'AGE',\n",
              " 'LBL_STATUT_CLT',\n",
              " 'LBL_GEO_AIR',\n",
              " 'LBL_GRP_SEGMENT_NL',\n",
              " 'LBL_SEG_COMPORTEMENTAL',\n",
              " 'LBL_GEO_TRAIN',\n",
              " 'LBL_SEGMENT_ANTICIPATION',\n",
              " 'FLG_CMD_CARTE_1225']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "histo_client_raw.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HEZBFyr0uCR",
        "outputId": "f14cc4f9-7c15-4c51-d991-7d4c20e35d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+----+----------+-----------+\n",
            "| AGE|anciennete|recence_cmd|\n",
            "+----+----------+-----------+\n",
            "|null|      1550|         36|\n",
            "|35.0|      1667|         25|\n",
            "|25.0|       395|         15|\n",
            "|31.0|      2188|         20|\n",
            "|32.0|      3005|         15|\n",
            "|25.0|      2094|          6|\n",
            "|21.0|       153|         31|\n",
            "|25.0|      1329|         33|\n",
            "|20.0|      1236|          3|\n",
            "|null|      3591|         13|\n",
            "+----+----------+-----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "histo_client_raw.select('AGE','anciennete','recence_cmd').show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k_r5syt0uCR"
      },
      "source": [
        "toutes les colonnes de ce dataframe sont continues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5TqgpGD0uCS",
        "outputId": "61d3f8af-6509-4d63-fcd6-f58cb3ada921"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ID_CLIENT',\n",
              " 'nb_od',\n",
              " 'mean_nb_passagers',\n",
              " 'mean_duree_voyage',\n",
              " 'mean_mt_voyage',\n",
              " 'mean_tarif_loisir',\n",
              " 'mean_classe_1',\n",
              " 'mean_pointe',\n",
              " 'mean_depart_we']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "histo_train_raw.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyynRWA80uCS"
      },
      "source": [
        "Toutes les colonnes constituants ce dataframe sont également continues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awK8CJBZ0uCS",
        "outputId": "04c92e36-d4cf-49e1-b7e1-f7243d135b32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---------------+--------------------+------------+\n",
            "|           ID_CLIENT|flg_cmd_lowcost|flg_track_nl_lowcost|flg_track_nl|\n",
            "+--------------------+---------------+--------------------+------------+\n",
            "|003fb9dca8de37438...|              1|                   0|           1|\n",
            "|0225a0a30f58ab70d...|              1|                   0|           0|\n",
            "|024110078fb4581a7...|              1|                   0|           1|\n",
            "|028fd9538c6857cad...|              1|                   0|           0|\n",
            "|04a57657f50047cf8...|              1|                   0|           0|\n",
            "+--------------------+---------------+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "histo_lowcost_raw.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fq6345wY0uCT",
        "outputId": "609b2fd4-0987-4bf0-c440-d620c7bf35c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+------+\n",
            "|flg_cmd_lowcost| count|\n",
            "+---------------+------+\n",
            "|              1|104306|\n",
            "+---------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "histo_lowcost_raw.groupby('flg_cmd_lowcost').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgqeU1Px0uCT",
        "outputId": "3a44ebdf-2764-4f2a-bdce-67d6e20af6f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|flg_track_nl_lowcost|count|\n",
            "+--------------------+-----+\n",
            "|                   0|90641|\n",
            "|                   1|13665|\n",
            "+--------------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "histo_lowcost_raw.groupby('flg_track_nl_lowcost').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3Ln0pk-0uCU",
        "outputId": "7c83fbc8-e39b-44e8-e5fa-3a8f082dec95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+-----+\n",
            "|flg_track_nl|count|\n",
            "+------------+-----+\n",
            "|           0|36443|\n",
            "|           1|67863|\n",
            "+------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "histo_lowcost_raw.groupby('flg_track_nl').count().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHNAJ5Ev0uCU"
      },
      "source": [
        "les colonnes dans ce dataframe représentent des labels donc des variables qualitatives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0r66qQ20uCU",
        "outputId": "e45e2b93-f63a-4003-819d-bb2c142f13f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+---------------------+-------------------+\n",
            "|           ID_CLIENT|days_since_last_visit|      tx_conversion|\n",
            "+--------------------+---------------------+-------------------+\n",
            "|000843db32fbaecfb...|                    8| 0.1111111111111111|\n",
            "|001338752ea32d9de...|                    3|0.13043478260869565|\n",
            "|003fb9dca8de37438...|                   15|                1.0|\n",
            "|004efa6652e570ef6...|                   17|              0.125|\n",
            "|005dd0b718a8f4598...|                   15| 0.3333333333333333|\n",
            "+--------------------+---------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "visites_raw.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upgMHHta0uCV"
      },
      "source": [
        "Les colonnes de ce dataframe représentent des variables continues"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otqv5Q9N0uCV"
      },
      "outputs": [],
      "source": [
        "## ecrire une fonction pour transformer les features quantitatives (\"anciennete\", \"recence_cmd\", \"AGE\", etc..) en float"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "scrolled": false,
        "id": "5dbhrQwO0uCV"
      },
      "outputs": [],
      "source": [
        "def cast_columns_of_df(df, cols_to_cast, col_to_keep, cast_type='double'):\n",
        "    \"\"\"cast continuous columns into double since all columns are \"\"\"\n",
        "    return df.select(col_to_keep + [(df[feature].cast(cast_type))\n",
        "                    for feature in cols_to_cast if 'ID_CLIENT' not in feature])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-GzPnEe0uCW"
      },
      "outputs": [],
      "source": [
        "client_cols_to_keep = [\"ID_CLIENT\", 'LBL_STATUT_CLT','LBL_GEO_AIR',\n",
        "            'LBL_SEG_COMPORTEMENTAL','LBL_GEO_TRAIN','LBL_GRP_SEGMENT_NL',\n",
        "            'LBL_SEGMENT_ANTICIPATION','FLG_CMD_CARTE_1225','recence_cmd']\n",
        "\n",
        "\n",
        "histo_client = cast_columns_of_df(histo_client_raw,\n",
        "                                  [\"anciennete\",\"AGE\"],\n",
        "                                  client_cols_to_keep,\n",
        "                                 cast_type='int')\n",
        "\n",
        "client_cols_to_keep = [\"ID_CLIENT\", 'LBL_STATUT_CLT','LBL_GEO_AIR',\n",
        "            'LBL_SEG_COMPORTEMENTAL','LBL_GEO_TRAIN','LBL_GRP_SEGMENT_NL',\n",
        "            'LBL_SEGMENT_ANTICIPATION','FLG_CMD_CARTE_1225','anciennete','AGE']\n",
        "\n",
        "histo_client = cast_columns_of_df(histo_client,\n",
        "                                  [\"recence_cmd\"],\n",
        "                                  client_cols_to_keep,\n",
        "                                 cast_type='double')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFbGvL7L0uCW"
      },
      "outputs": [],
      "source": [
        "\n",
        "histo_train = cast_columns_of_df(histo_train_raw, histo_train_raw.columns,\n",
        "                                 [\"ID_CLIENT\"], cast_type='double')\n",
        "\n",
        "train_to_keep = [\"ID_CLIENT\",\"mean_nb_passagers\", \"mean_duree_voyage\", \"mean_mt_voyage\", \n",
        "                 \"mean_tarif_loisir\" ,\"mean_classe_1\" ,\"mean_pointe\", \"mean_depart_we\"]\n",
        "\n",
        "histo_train = cast_columns_of_df(histo_train, [\"nb_od\"],\n",
        "                                 train_to_keep, cast_type = 'int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9icQAOV0uCW"
      },
      "outputs": [],
      "source": [
        "histo_lowcost = cast_columns_of_df(histo_lowcost_raw, histo_lowcost_raw.columns,\n",
        "                                 [\"ID_CLIENT\"], cast_type='int')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQ5AutpX0uCW"
      },
      "outputs": [],
      "source": [
        "visites = cast_columns_of_df(visites_raw, [\"days_since_last_visit\"],\n",
        "                             [\"ID_CLIENT\",\"tx_conversion\"], \n",
        "                             cast_type='int')\n",
        "\n",
        "visites = cast_columns_of_df(visites_raw, [\"tx_conversion\"],\n",
        "                             [\"ID_CLIENT\",\"days_since_last_visit\"], \n",
        "                             cast_type='double')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJa4h0ET0uCW"
      },
      "source": [
        "faire une jointure entre les informations des différentes tables.\n",
        "NB: on conservera tous les clients de la table perimetre.\n",
        "    En effet, ce sont les cleints qu'on souhaite scorer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rs67JK4y0uCX"
      },
      "outputs": [],
      "source": [
        "df = perimetre\\\n",
        "    .join(histo_client, on = 'ID_CLIENT', how = 'left_outer')\\\n",
        "    .join(histo_train, on = 'ID_CLIENT', how = 'left_outer')\\\n",
        "    .join(histo_lowcost, on = 'ID_CLIENT', how = 'left_outer')\\\n",
        "    .join(visites, on = 'ID_CLIENT', how = 'left_outer')\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjBLiJwk0uCX"
      },
      "source": [
        "combien a t'on de features quatitatives, qualitatives "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij72iVnB0uCX",
        "outputId": "f5461e33-358e-4222-e7c1-ae722e79b05a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Variables qualitatives : 8\n",
            "Variables quantitatives : 16\n"
          ]
        }
      ],
      "source": [
        "#Fonction pour compter le nombre de variables qualitatives et quantitatives\n",
        "def count_types_col(df, ignored_col):\n",
        "    quali = 0\n",
        "    quanti = 0\n",
        "    for col in df.columns:\n",
        "        if col not in ignored_col and df.select(col).dtypes[0][1] == 'string':\n",
        "            quali += 1\n",
        "        else:\n",
        "            quanti += 1\n",
        "    return quanti,quali\n",
        "\n",
        "compt = count_types_col(df,['ID_CLIENT'])\n",
        "print(\"Variables qualitatives : {}\".format(compt[1]))\n",
        "print(\"Variables quantitatives : {}\".format(compt[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXpmJYR_0uCX"
      },
      "source": [
        "quelles sont les differentes modalites de la feature LBL_STATUT_CLT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIUGzZRE0uCX",
        "outputId": "d7d1d25c-123d-4411-a715-4d09967848d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(LBL_STATUT_CLT='Moyen moins'),\n",
              " Row(LBL_STATUT_CLT='Non present dans la base a cette date'),\n",
              " Row(LBL_STATUT_CLT='Nouveau prospect'),\n",
              " Row(LBL_STATUT_CLT='Prospect'),\n",
              " Row(LBL_STATUT_CLT='Tres petit'),\n",
              " Row(LBL_STATUT_CLT=None),\n",
              " Row(LBL_STATUT_CLT='Petit'),\n",
              " Row(LBL_STATUT_CLT='Inactif'),\n",
              " Row(LBL_STATUT_CLT='Nouveau actif'),\n",
              " Row(LBL_STATUT_CLT='Grand'),\n",
              " Row(LBL_STATUT_CLT='Tres grand'),\n",
              " Row(LBL_STATUT_CLT='Moyen plus')]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Modalités de la variable LBL_STATUT_CLT\n",
        "df.select('LBL_STATUT_CLT').distinct().collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk641XTg0uCY"
      },
      "source": [
        "quelles sont les features avec valeurs manquantes\n",
        "remplacer les valeurs manquantes par -1 pour toutes les features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLQq5bef0uCY",
        "outputId": "e5312c0b-19cb-4af3-c47e-ee97d689d03e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID_CLIENT</th>\n",
              "      <th>LBL_STATUT_CLT</th>\n",
              "      <th>LBL_GEO_AIR</th>\n",
              "      <th>LBL_SEG_COMPORTEMENTAL</th>\n",
              "      <th>LBL_GEO_TRAIN</th>\n",
              "      <th>LBL_GRP_SEGMENT_NL</th>\n",
              "      <th>LBL_SEGMENT_ANTICIPATION</th>\n",
              "      <th>FLG_CMD_CARTE_1225</th>\n",
              "      <th>anciennete</th>\n",
              "      <th>AGE</th>\n",
              "      <th>...</th>\n",
              "      <th>mean_tarif_loisir</th>\n",
              "      <th>mean_classe_1</th>\n",
              "      <th>mean_pointe</th>\n",
              "      <th>mean_depart_we</th>\n",
              "      <th>nb_od</th>\n",
              "      <th>flg_cmd_lowcost</th>\n",
              "      <th>flg_track_nl_lowcost</th>\n",
              "      <th>flg_track_nl</th>\n",
              "      <th>days_since_last_visit</th>\n",
              "      <th>tx_conversion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>78998</td>\n",
              "      <td>162977</td>\n",
              "      <td>155160</td>\n",
              "      <td>163010</td>\n",
              "      <td>79522</td>\n",
              "      <td>157822</td>\n",
              "      <td>10283</td>\n",
              "      <td>55</td>\n",
              "      <td>169311</td>\n",
              "      <td>...</td>\n",
              "      <td>62370</td>\n",
              "      <td>49927</td>\n",
              "      <td>49927</td>\n",
              "      <td>49927</td>\n",
              "      <td>49927</td>\n",
              "      <td>979911</td>\n",
              "      <td>979911</td>\n",
              "      <td>979911</td>\n",
              "      <td>64142</td>\n",
              "      <td>64142</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID_CLIENT  LBL_STATUT_CLT  LBL_GEO_AIR  LBL_SEG_COMPORTEMENTAL  \\\n",
              "0          0           78998       162977                  155160   \n",
              "\n",
              "   LBL_GEO_TRAIN  LBL_GRP_SEGMENT_NL  LBL_SEGMENT_ANTICIPATION  \\\n",
              "0         163010               79522                    157822   \n",
              "\n",
              "   FLG_CMD_CARTE_1225  anciennete     AGE      ...        mean_tarif_loisir  \\\n",
              "0               10283          55  169311      ...                    62370   \n",
              "\n",
              "   mean_classe_1  mean_pointe  mean_depart_we  nb_od  flg_cmd_lowcost  \\\n",
              "0          49927        49927           49927  49927           979911   \n",
              "\n",
              "   flg_track_nl_lowcost  flg_track_nl  days_since_last_visit  tx_conversion  \n",
              "0                979911        979911                  64142          64142  \n",
              "\n",
              "[1 rows x 24 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Fonction pour compter le nombre de valeurs manquantes dans chaque features\n",
        "def count_nan_values(df):\n",
        "    from pyspark.sql.functions import col, sum\n",
        "    return df.select(*(sum(col(c).isNull().cast('int')).alias(c) for c in df.columns)).toPandas()\n",
        "    \n",
        "count_nan_values(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3-_5YhR0uCY"
      },
      "outputs": [],
      "source": [
        "##Fonction pour remplacer les valeurs manquantes par -1 pour les variables qualtatives \n",
        "##et la moyenne pour celles qui sont quantitatives\n",
        "def replace_missing_val(df,qualifies_columns, continuous_columns):\n",
        "    \n",
        "    return df.select([f.when(df[feature].isNotNull(), df[feature])\\\n",
        "                      .otherwise('-1').alias(feature) for feature in qualifies_columns]\\\n",
        "                     +[f.when(df[feature].isNotNull(), df[feature])\\\n",
        "                       .otherwise(df.select(f.mean(df[feature])).collect()[0][0])\\\n",
        "                       .alias(feature) for feature in continuous_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ym8vh9ac0uCY"
      },
      "outputs": [],
      "source": [
        "#def replace_missing_val2(df,qualifies_columns, continuous_columns):\n",
        "#    dict_mean = {feat: df.select(f.mean(feat)).collect()[0][0] \n",
        "#                 for feat in continuous_columns}\n",
        "#    return df.select([f.when(df[feature].isNotNull(), df[feature])\\\n",
        "#                      .otherwise('-1').alias(feature) for feature in qualifies_columns]\\\n",
        "#                     +[f.when(df[feature].isNotNull(), df[feature])\\\n",
        "#                       .otherwise(dict_mean[feature]).alias(feature) \n",
        "#                       for feature in continuous_columns])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-IeUEAR0uCZ"
      },
      "outputs": [],
      "source": [
        "qualifies_columns = [\"ID_CLIENT\", 'LBL_STATUT_CLT','LBL_GEO_AIR',\n",
        "            'LBL_SEG_COMPORTEMENTAL','LBL_GEO_TRAIN','LBL_GRP_SEGMENT_NL',\n",
        "            'LBL_SEGMENT_ANTICIPATION','FLG_CMD_CARTE_1225','flg_cmd_lowcost']\n",
        "\n",
        "continuous_columns = list(set(df.columns).difference(set(qualifies_columns)))\n",
        "\n",
        "\n",
        "df = replace_missing_val(df, qualifies_columns,continuous_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "256wbztL0uCZ"
      },
      "outputs": [],
      "source": [
        "def input_df(df):\n",
        "    ds = df.select('ID_CLIENT',\n",
        "    f.when(df.LBL_GEO_TRAIN.isin(['Toulouse', 'Lille', 'Dijon',\n",
        "                                  'Lyon', 'Marseille', 'Paris',\n",
        "                                  'Nice', 'Limoges','Rouen','Rennes',\n",
        "                                  'Montpellier', 'Bordeaux', 'Metz',\n",
        "                                  'Strasbourg']), df.LBL_GEO_TRAIN)\\\n",
        "               .otherwise('na').alias('geo_train'),\n",
        "    f.when(df.LBL_GEO_AIR.isin(['Aéroports de Paris Orly',\n",
        "                                'Aéroport de Bâle-Mulhouse / Bassel',\n",
        "                                'Aéroport Lille Lesquin', 'Aéroport de Rennes',\n",
        "                                'Aéroport de Nantes Atlantique',\n",
        "                                'Aéroport de Marseille Provence  (MRS)', \n",
        "                                'Aéroport de Bordeaux Mérignac',\n",
        "                                'Aéroports de Paris Roissy-Charles-de Gaulle', \n",
        "                                \"Aéroport de Nice Côte d'Azur\",\n",
        "                                'Aéroport de Strasbourg',\n",
        "                                'Aéroport de Lyon - Saint Exupéry', \n",
        "                                'Aéroport de Toulouse Blagnac']), df.LBL_GEO_AIR)\\\n",
        "               .otherwise('na').alias('geo_air'),\n",
        "    f.when(df.FLG_CMD_CARTE_1225 == '1', '1')\\\n",
        "                   .otherwise('0').alias('cc_jeunes'),\n",
        "    f.when(df.LBL_STATUT_CLT.isin(['Tres grand', 'Nouveau actif',\n",
        "                                   'Moyen moins', ' Prospect', ' Petit',\n",
        "                                   'Inactif', 'Tres petit',\n",
        "                                   'Nouveau prospect', 'Moyen plus',\n",
        "                                   'Grand']), df.LBL_STATUT_CLT)\\\n",
        "                   .otherwise('na').alias('segt_rfm'),\n",
        "    f.when(df.LBL_SEGMENT_ANTICIPATION.isin(['Peu Anticipateur', 'Tres Anticipateur',\n",
        "                                             'Anticipateur', 'Mixte', 'Non Anticipateur',\n",
        "                                             'Non Defini']), df.LBL_SEGMENT_ANTICIPATION)\\\n",
        "                   .otherwise('na').alias('segt_anticipation'),\n",
        "    f.when(df.LBL_SEG_COMPORTEMENTAL.isin(['Mono-commande',\n",
        "                                           'Comportement Pro',\n",
        "                                           'Exclusifs Agence', \n",
        "                                           'Anticipateurs Methodiques',\n",
        "                                           'Chasseurs Bons Plans', \n",
        "                                           'Rythmes scolaires', 'Nouveaux',\n",
        "                                           'Sans contraintes']),\n",
        "           df.LBL_SEG_COMPORTEMENTAL).otherwise('na').alias('segt_comportemental'), \n",
        "    f.when(df.LBL_GRP_SEGMENT_NL.isin(['Endormi', 'Spectateur', 'Acteur',\n",
        "                                       'Eteint', 'Non defini']),\n",
        "           df.LBL_GRP_SEGMENT_NL).otherwise('na').alias('segt_nl'),\n",
        "    f.when(((df.AGE > 0) & (df.AGE < 100)), df.AGE)\\\n",
        "                   .otherwise(-1).alias('age'),\n",
        "    f.when(df.recence_cmd >= 0, df.recence_cmd)\\\n",
        "                   .otherwise(-1).alias('recence_cmd'),\n",
        "    f.when(((df.mean_duree_voyage > 0) & (df.mean_duree_voyage < 750)),\n",
        "           df.mean_duree_voyage).otherwise(-1).alias('mean_duree_voyage'),\n",
        "    f.when(df.days_since_last_visit >= 0, df.days_since_last_visit)\\\n",
        "                   .otherwise(-1).alias('recence_visite'),\n",
        "    f.when(df.mean_mt_voyage > 0, df.mean_mt_voyage)\\\n",
        "                   .otherwise(-1).alias('mean_mt_voyage'),\n",
        "    f.when(df.anciennete >= 0, df.anciennete)\\\n",
        "                   .otherwise(-1).alias('anciennete'),\n",
        "    f.when(df.nb_od > 0, df.nb_od)\\\n",
        "                   .otherwise(-1).alias('nb_od'),\n",
        "    f.when(df.mean_nb_passagers > 0, df.mean_nb_passagers)\\\n",
        "                   .otherwise(-1).alias('mean_nb_passagers'),\n",
        "    f.when(df.mean_tarif_loisir >= 0, df.mean_tarif_loisir)\\\n",
        "                   .otherwise(-1).alias('mean_tarif_loisir'),\n",
        "    f.when(df.mean_classe_1 >= 0, df.mean_classe_1)\\\n",
        "                   .otherwise(-1).alias('mean_classe_1'),\n",
        "    f.when(df.mean_pointe >= 0, df.mean_pointe)\\\n",
        "                   .otherwise(-1).alias('mean_pointe'),\n",
        "    f.when(df.mean_depart_we >= 0, df.mean_depart_we)\\\n",
        "                   .otherwise(-1).alias('mean_depart_we'),\n",
        "    f.when(df.tx_conversion >= 0, df.tx_conversion)\\\n",
        "                   .otherwise(-1).alias('tx_conversion'),\n",
        "    f.when(df.flg_cmd_lowcost == 1, '1')\\\n",
        "                   .otherwise('0').alias('flg_cmd_lowcost'),\n",
        "    f.when(df.flg_track_nl_lowcost == 1, '1')\\\n",
        "                   .otherwise('0').alias('flg_track_nl_lowcost'), \n",
        "    f.when(df.flg_track_nl == 1, '1')\\\n",
        "                   .otherwise('0').alias('flg_track_nl'))\n",
        "    \n",
        "    return ds\n",
        "df1 = input_df(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q1YxIdQ0uCZ"
      },
      "source": [
        "Quelles sont les differentes valeurs de notre label : flg_cmd_lowcost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-VRBihI0uCa",
        "outputId": "baabe2e8-8e18-4e4b-dcad-80aeaf1d1d42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------+------+\n",
            "|flg_cmd_lowcost| count|\n",
            "+---------------+------+\n",
            "|              0|979911|\n",
            "|              1|104306|\n",
            "+---------------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df1.groupby('flg_cmd_lowcost').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "EuAX77B_0uCa"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, VectorIndexer\n",
        "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "nNyNLvYn0uCa"
      },
      "source": [
        "- VectorAssembler permet de merger plusieurs colonnes pour en faire un vecteur.\n",
        "    -inputCols : argument permettant de donner la liste des noms des colonnes que l'on \n",
        "    veut assembler\n",
        "    -ouputCol : argument pour donner le nom de la colonne contenant le nouveau vecteur \n",
        "    créé\n",
        "\n",
        "- VectorIndexer permet de dummifier les variables catégorielles en déterminant celles qui \n",
        "  le sont par le nombre de modalités qu'elles ont.\n",
        "    - maxCategories permet de donner le nombre max de  modalités qu'une variable \n",
        "    catégorielle doit avoir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWsoizY_0uCa"
      },
      "source": [
        "##### features engineering et modélisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xpeuBFix0uCa"
      },
      "outputs": [],
      "source": [
        "\n",
        "def preprocessed_df(df, label=\"flg_cmd_lowcostIndex\"):\n",
        "    max_values_to_define_str_cols = 10\n",
        "    id_col = 'ID_CLIENT'\n",
        "    \n",
        "    dty = dict(df.dtypes)\n",
        "    str_cols = [k for k, v in dty.items() if v == 'string']\n",
        "    str_cols.remove(id_col)\n",
        "    \n",
        "    for c in str_cols:\n",
        "        stringIndexer = StringIndexer(inputCol=c, outputCol=c+\"Index\")\n",
        "        model_str = stringIndexer.fit(df)\n",
        "        df = model_str.transform(df).drop(c)\n",
        "\n",
        "    input_cols = df.columns\n",
        "    input_cols.remove(id_col)\n",
        "    input_cols.remove(label)\n",
        "    \n",
        "    assembler = VectorAssembler(inputCols=input_cols,\n",
        "                            outputCol=\"features\")\n",
        "    df = assembler.transform(df)\n",
        "    \n",
        "    featureIndexer = VectorIndexer(inputCol=\"features\", \n",
        "                   outputCol=\"indexedFeatures\", \n",
        "                   maxCategories=max_values_to_define_str_cols).fit(df)\n",
        "    return featureIndexer.transform(df), df\n",
        "\n",
        "\n",
        "data, dff = preprocessed_df(df1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NwfARUo0uCa",
        "outputId": "25a48cc4-a05d-4dfa-bf29-107a9a2f0a67"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(ID_CLIENT='000843db32fbaecfbb047ca0bb04b1f9f4d9425a', age=36.77269796022761, recence_cmd=36.0, mean_duree_voyage=274.6666666666667, mean_mt_voyage=58.666666666666664, anciennete=1550.0, nb_od=1.0, mean_nb_passagers=1.0, mean_tarif_loisir=0.0, mean_classe_1=0.0, mean_pointe=0.0, mean_depart_we=0.0, tx_conversion=0.1111111111111111, geo_trainIndex=0.0, geo_airIndex=2.0, cc_jeunesIndex=0.0, segt_rfmIndex=2.0, segt_anticipationIndex=4.0, segt_comportementalIndex=6.0, segt_nlIndex=1.0, recence_visiteIndex=7.0, flg_cmd_lowcostIndex=0.0, flg_track_nl_lowcostIndex=0.0, flg_track_nlIndex=0.0, features=DenseVector([36.7727, 36.0, 274.6667, 58.6667, 1550.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1111, 0.0, 2.0, 0.0, 2.0, 4.0, 6.0, 1.0, 7.0, 0.0, 0.0]), indexedFeatures=DenseVector([36.7727, 36.0, 274.6667, 58.6667, 1550.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1111, 0.0, 2.0, 0.0, 2.0, 4.0, 6.0, 1.0, 7.0, 0.0, 0.0]))]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.take(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HPM3Pua0uCb",
        "outputId": "42ed4d70-6167-478b-d751-273d65a8ea77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Row(ID_CLIENT='000843db32fbaecfbb047ca0bb04b1f9f4d9425a', age=36.77269796022761, recence_cmd=36.0, mean_duree_voyage=274.6666666666667, mean_mt_voyage=58.666666666666664, anciennete=1550.0, nb_od=1.0, mean_nb_passagers=1.0, mean_tarif_loisir=0.0, mean_classe_1=0.0, mean_pointe=0.0, mean_depart_we=0.0, tx_conversion=0.1111111111111111, geo_trainIndex=0.0, geo_airIndex=2.0, cc_jeunesIndex=0.0, segt_rfmIndex=2.0, segt_anticipationIndex=4.0, segt_comportementalIndex=6.0, segt_nlIndex=1.0, recence_visiteIndex=7.0, flg_cmd_lowcostIndex=0.0, flg_track_nl_lowcostIndex=0.0, flg_track_nlIndex=0.0, features=DenseVector([36.7727, 36.0, 274.6667, 58.6667, 1550.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.1111, 0.0, 2.0, 0.0, 2.0, 4.0, 6.0, 1.0, 7.0, 0.0, 0.0]))]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dff.take(1)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "FPSOc_rg0uCb"
      },
      "source": [
        "Créer une fonction\n",
        "compute_model(df,model,labelcol,featurecol):\n",
        "Cette fonction partage les données en train et test et renvoie un dictionnaire avec l'auc, le score,\n",
        "recall, precision et la matrice de confusion selon que le modèle choisi soit la regression logistique ou le randomForest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F5FpS8ie0uCb"
      },
      "outputs": [],
      "source": [
        "df_sample = data.sampleBy(\"flg_cmd_lowcostIndex\",{0:0.1,1:0.2}, seed = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR3yddXD0uCb",
        "outputId": "80ae8c70-6627-464f-b23f-bbfbad326c6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+-----+\n",
            "|flg_cmd_lowcostIndex|count|\n",
            "+--------------------+-----+\n",
            "|                 0.0|98072|\n",
            "|                 1.0|20922|\n",
            "+--------------------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_sample.groupby('flg_cmd_lowcostIndex').count().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rT_4LUa0uCb"
      },
      "outputs": [],
      "source": [
        "def compute_model(df,model,labelcol,featurescol,weightSplit,**kwargs):\n",
        "    \n",
        "    from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
        "    from pyspark.mllib.evaluation import MulticlassMetrics\n",
        "    from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "    #cut data according the rate *weightSplit* for the test\n",
        "    train,test = df.randomSplit([1-weightSplit,weightSplit], seed = 2)\n",
        "    \n",
        "    #In the logistic regression case\n",
        "    if model == 'lr':\n",
        "        if 'elasticNetParam' is kwargs:\n",
        "            el = kwargs['elasticNetParam']\n",
        "        else:\n",
        "            el = 0.5\n",
        "        lr = LogisticRegression(labelCol = labelcol,\n",
        "                               featuresCol = featurescol,\n",
        "                               elasticNetParam = el)\n",
        "        #Fitting model for logistic regression\n",
        "        ourmodel = lr.fit(train)\n",
        "    \n",
        "    #In the randomForest case\n",
        "    elif model == 'rf':\n",
        "        if 'numTrees' in kwargs:\n",
        "            numTrees = kwargs['numTrees']\n",
        "        else: #default value for numTrees\n",
        "            numTrees = 20\n",
        "            \n",
        "        if 'maxDepth' in kwargs:\n",
        "            maxDepth = kwargs['maxDepth']\n",
        "        else: #default value for maxDepth\n",
        "            maxDepth = 5\n",
        "            \n",
        "        if 'minInstancesPerNode' in kwargs:\n",
        "            minInstancesPerNode = kwargs['minInstancesPerNode']\n",
        "        else: #default value for minInstancesPernode\n",
        "            minInstancesPerNode = 1     \n",
        "            \n",
        "        if 'featureSubsetStrategy' in kwargs:\n",
        "            featureSubsetStrategy = kwargs['featureSubsetStrategy']\n",
        "        else: #default value for featureSubsetStrategy\n",
        "            featureSubsetStrategy = 'auto'\n",
        "        \n",
        "        rf = RandomForestClassifier(featuresCol = featurescol, labelCol = labelcol,\n",
        "                                    minInstancesPerNode = minInstancesPerNode, numTrees = numTrees, \n",
        "                                    featureSubsetStrategy = featureSubsetStrategy, maxBins = 63)\n",
        "        #Fitting model for random Forest    \n",
        "        ourmodel = rf.fit(train)\n",
        "    \n",
        "    else : \n",
        "        print(\"Choix indisponible. Veuillez choisir 'lr'ou 'rf'. \")\n",
        "    \n",
        "    #Calcul de la prediction\n",
        "    if model in ['rf','lr']:\n",
        "    \n",
        "        #prediction test set\n",
        "        pred = ourmodel.transform(test)\n",
        "        \n",
        "        #Computing of the performance indices\n",
        "        predictionAndLabels = pred.select('prediction',labelcol).rdd\n",
        "        \n",
        "        perf = dict()\n",
        "        perf['AUC'] = BinaryClassificationEvaluator(rawPredictionCol='prediction',\n",
        "                                           labelCol='flg_cmd_lowcostIndex',\n",
        "                                          metricName = 'areaUnderROC').evaluate(pred)\n",
        "        metrics = MulticlassMetrics(predictionAndLabels)\n",
        "        perf['accuracy'] = metrics.accuracy\n",
        "        perf['confu_matrix'] = metrics.confusionMatrix().toArray()\n",
        "        \n",
        "        #Notre label d'interet est '1' \n",
        "        perf['precision'] = metrics.precision(1)\n",
        "        perf['recall'] = metrics.recall(1)\n",
        "        \n",
        "    return perf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fx-OYSR0uCc",
        "outputId": "888715ca-6cf9-4e2f-c8a7-06fbe0c8b53e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Logitic Regression\n",
            "[[2.438e+04 3.000e+00]\n",
            " [1.819e+03 3.393e+03]]\n"
          ]
        }
      ],
      "source": [
        "#Logistic regression model\n",
        "performance = compute_model(df_sample,\"lr\", \"flg_cmd_lowcostIndex\",\"indexedFeatures\",weightSplit=0.25)\n",
        "print(\"Confusion Matrix for Logitic Regression\")\n",
        "print(performance['confu_matrix'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GT_6UnD0uCc",
        "outputId": "67642a8f-c3da-408f-fcf6-ec560ee0b9ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logistic Regression performance\n",
            "-------------------------------\n",
            "AUC : 0.825437330539511\n",
            "accuracy : 0.9384355465450245\n",
            "precision : 0.9991166077738516\n",
            "recall : 0.6509976976208749\n"
          ]
        }
      ],
      "source": [
        "print(\"Logistic Regression performance\")\n",
        "print(\"-------------------------------\")\n",
        "for ind,val in performance.items():\n",
        "    if ind != 'confu_matrix':\n",
        "        print(\"{} : {}\".format(ind,val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF2loyeZ0uCc",
        "outputId": "2cfd33df-02cd-4863-e1c7-29dea0e46407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix for RandomForest\n",
            "[[24383.     0.]\n",
            " [ 1819.  3393.]]\n"
          ]
        }
      ],
      "source": [
        "#RandomForest model\n",
        "performance = compute_model(df_sample,\"rf\", \"flg_cmd_lowcostIndex\",\"indexedFeatures\",weightSplit=0.25)\n",
        "print(\"Confusion Matrix for RandomForest\")\n",
        "print(performance['confu_matrix'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAqU7v_Q0uCc",
        "outputId": "7b1d4a09-9402-46a6-88d2-8305ce78d328"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest performance\n",
            "-------------------------\n",
            "AUC : 0.8254988488104374\n",
            "accuracy : 0.9385369150194289\n",
            "precision : 1.0\n",
            "recall : 0.6509976976208749\n"
          ]
        }
      ],
      "source": [
        "print(\"Random Forest performance\")\n",
        "print(\"-------------------------\")\n",
        "for ind,val in performance.items():\n",
        "    if ind != 'confu_matrix':\n",
        "        print(\"{} : {}\".format(ind,val))"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "score_lowcost_cor.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}